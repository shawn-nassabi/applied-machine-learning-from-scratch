{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a16641-c2e7-42a3-94e9-daba3d577841",
   "metadata": {},
   "source": [
    "## Miniproject 3 - Decision Trees, by Shawn Nassabi (san7522)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b96d62e-3e19-45e9-88f2-59985ceb7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9511f3c-fe50-45de-8ac9-cb26941dc7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv(\"iris.csv\", names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"])\n",
    "iris_df= iris_df.replace({'Iris-setosa':0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e03f63e0-627f-4254-85c9-1194e55ffd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      sepal_length  sepal_width  petal_length  petal_width  class\n",
       "0             5.1          3.5           1.4          0.2      0\n",
       "1             4.9          3.0           1.4          0.2      0\n",
       "2             4.7          3.2           1.3          0.2      0\n",
       "3             4.6          3.1           1.5          0.2      0\n",
       "4             5.0          3.6           1.4          0.2      0\n",
       "..            ...          ...           ...          ...    ...\n",
       "145           6.7          3.0           5.2          2.3      2\n",
       "146           6.3          2.5           5.0          1.9      2\n",
       "147           6.5          3.0           5.2          2.0      2\n",
       "148           6.2          3.4           5.4          2.3      2\n",
       "149           5.9          3.0           5.1          1.8      2\n",
       "\n",
       "[150 rows x 5 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(iris_df.shape) # 150, 5, 5th is the target\n",
    "iris_df.head\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21293101-fcf6-44f4-9b8a-e0613cafb042",
   "metadata": {},
   "source": [
    "## Decision tree and its methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ae7edb-05b8-482b-a582-db18386933fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self, col=None, crit=None):\n",
    "        self.col = col\n",
    "        self.crit = crit\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.isLeaf = False\n",
    "        self.res = None\n",
    "\n",
    "\n",
    "\n",
    "class decision_tree:\n",
    "    def __init__(self, minLimit):\n",
    "        self.root = node()\n",
    "        self.minLimit = minLimit\n",
    "        self.minAmount = None\n",
    "\n",
    "    def get_entropy(self, targetCol):\n",
    "        entropy = 0\n",
    "        total_length = len(targetCol)\n",
    "        target_counts = targetCol.value_counts()\n",
    "        probabilities = target_counts/total_length\n",
    "        for p in probabilities:\n",
    "            if p != 0:\n",
    "                entropy += p * np.log2(p)\n",
    "    \n",
    "        return -entropy\n",
    "        \n",
    "    def get_info_gain(self, colName, crit, parent, target):\n",
    "        leftSplit = parent[parent[colName] < crit]\n",
    "        rightSplit = parent[parent[colName] >= crit]\n",
    "        parent_entropy = self.get_entropy(parent[target])\n",
    "        left_entropy = self.get_entropy(leftSplit[target])\n",
    "        right_entropy = self.get_entropy(rightSplit[target])\n",
    "        length = parent.shape[0]\n",
    "        IG = parent_entropy - ((leftSplit.shape[0]/length)*left_entropy + (rightSplit.shape[0]/length)*right_entropy)\n",
    "        return IG\n",
    "\n",
    "    def get_best_crit(self,sample, colName, target): # Get the best criteria for the given column\n",
    "        highestIG = 0\n",
    "        bestCrit = None\n",
    "        u_crits, u_crits_occ = np.unique(sample[colName], return_counts=True)\n",
    "        for c in u_crits:\n",
    "            ig = self.get_info_gain(colName, c, sample, target)\n",
    "            if ig >= highestIG:\n",
    "                highestIG = ig\n",
    "                bestCrit = c\n",
    "        return bestCrit\n",
    "\n",
    "    def get_best_col(self, sample, target): # Find the best column and the best criteria for it\n",
    "        \n",
    "        highestIG = 0\n",
    "        bestCol = None\n",
    "        bestCrit = None\n",
    "        for col in sample.columns:\n",
    "            if col == target:\n",
    "                continue\n",
    "            crit = self.get_best_crit(sample, col, target)\n",
    "            ig = self.get_info_gain(col, crit, sample, target)\n",
    "            if ig >= highestIG:\n",
    "                highestIG = ig\n",
    "                bestCol = col\n",
    "                bestCrit = crit\n",
    "        return bestCol, bestCrit\n",
    "\n",
    "    def train(self, curNode, sample, target):\n",
    "        #print(sample.shape[0])\n",
    "        if sample.shape[0] <= self.minAmount: # Min number of rows reached, so it is a leaf\n",
    "            curNode.isLeaf = True\n",
    "            unique_classes, unique_class_occurrences = np.unique(sample[target], return_counts=True)\n",
    "            bestClass = None\n",
    "            highestOcc = 0\n",
    "            for class_value, occurrence in zip(unique_classes, unique_class_occurrences): # Assign most occuring class as the bestClass\n",
    "                if occurrence > highestOcc:\n",
    "                    highestOcc = occurrence\n",
    "                    bestClass = class_value\n",
    "            curNode.res = bestClass\n",
    "            return\n",
    "            \n",
    "            \n",
    "        if self.get_entropy(sample[target]) == 0: # Entropy is 0 so it is a leaf\n",
    "            curNode.isLeaf = True\n",
    "            curNode.res = sample[target].mode().iloc[0] # assign the res as the only target value that is left\n",
    "            return\n",
    "\n",
    "        if not curNode.isLeaf:\n",
    "            col, crit = self.get_best_col(sample, target)\n",
    "            curNode.col = col\n",
    "            curNode.crit = crit\n",
    "            leftSplit = sample[sample[col] < crit]\n",
    "            rightSplit = sample[sample[col] >= crit]\n",
    "            curNode.left = node()\n",
    "            curNode.right = node()\n",
    "            self.train(curNode.left, leftSplit, target)\n",
    "            self.train(curNode.right, rightSplit, target)\n",
    "\n",
    "        \n",
    "        \n",
    "    def fit(self, data, target):\n",
    "        length = data.shape[0]\n",
    "        self.minAmount = length * (self.minLimit/100) # Calculate minimum amount threshold for leaf\n",
    "        self.train(self.root, data, target)\n",
    "\n",
    "    def predict(self, inputRow):\n",
    "        found = False\n",
    "        ptr = self.root\n",
    "        while not found:\n",
    "            if ptr.isLeaf: # If current ptr is a leaf then you have arrived at a prediction\n",
    "                found = True\n",
    "                break\n",
    "            if inputRow[ptr.col] < ptr.crit: # If less than current ptr's criteria then go left\n",
    "                ptr = ptr.left\n",
    "            else:\n",
    "                ptr = ptr.right \n",
    "        return ptr.res\n",
    "\n",
    "    def score(self, inputs, target):\n",
    "        length = inputs.shape[0]\n",
    "        correctCount = 0\n",
    "        for i in range(length):\n",
    "            prediction = self.predict(inputs.iloc[i])\n",
    "            if prediction == inputs[target][i]:\n",
    "                correctCount += 1\n",
    "        return correctCount / length\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# irisTree = decision_tree(5)\n",
    "# irisTree.fit(iris_df, \"class\")\n",
    "# prediction = irisTree.predict(iris_df.iloc[149])\n",
    "# print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744896d5-bb4f-43a4-9d79-f2f0194f44ee",
   "metadata": {},
   "source": [
    "## Training on iris dataset, using KFold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f60227e3-36ea-4b3c-84ed-7b62fb16dc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Min Thresholds  Accuracy Means  Std Deviations\n",
      "0               5        0.953333        0.052068\n",
      "1              10        0.953333        0.052068\n",
      "2              15        0.953333        0.052068\n",
      "3              20        0.953333        0.052068\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "IRIS_LIMITS = [5, 10, 15, 20] # Threshold limits to test\n",
    "iris_limit_means = []\n",
    "iris_limit_std = []\n",
    "\n",
    "for limit in IRIS_LIMITS:\n",
    "    accuracy_scores = []\n",
    "    for train_index, test_index in kf.split(iris_df): # Split iris dataset for kfold\n",
    "\n",
    "        iris_train, iris_test = iris_df.iloc[train_index], iris_df.iloc[test_index]\n",
    "\n",
    "        tree = decision_tree(limit) # Create decision tree with appropriate limit\n",
    "        target = iris_train.columns[-1]\n",
    "        tree.fit(iris_train, target) # fit the tree using the training data and last column as target\n",
    "\n",
    "        iris_pred = [tree.predict(row) for _, row in iris_test.iterrows()] # get predictions array\n",
    "\n",
    "        accuracy = accuracy_score(iris_test[target], iris_pred) # calculate accuracy scores\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    accuracy_mean = np.mean(accuracy_scores)\n",
    "    accuracy_std = np.std(accuracy_scores)\n",
    "    iris_limit_means.append(accuracy_mean)\n",
    "    iris_limit_std.append(accuracy_std)\n",
    "\n",
    "# print(IRIS_LIMITS)\n",
    "# print(limit_means)\n",
    "# print(limit_std)\n",
    "\n",
    "iris_table = pd.DataFrame({\n",
    "    'Min Thresholds': IRIS_LIMITS,\n",
    "    'Accuracy Means': iris_limit_means,\n",
    "    'Std Deviations': iris_limit_std\n",
    "})\n",
    "print(iris_table)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a940a7b-991c-4273-9ea6-648f2f97aabc",
   "metadata": {},
   "source": [
    "## Spambase Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb87d50-05f8-4b78-b423-54a1a012e78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9  \\\n",
       "0      0.21   0.28   0.50    0.0   0.14   0.28   0.21   0.07   0.00   0.94   \n",
       "1      0.06   0.00   0.71    0.0   1.23   0.19   0.19   0.12   0.64   0.25   \n",
       "2      0.00   0.00   0.00    0.0   0.63   0.00   0.31   0.63   0.31   0.63   \n",
       "3      0.00   0.00   0.00    0.0   0.63   0.00   0.31   0.63   0.31   0.63   \n",
       "4      0.00   0.00   0.00    0.0   1.85   0.00   0.00   1.85   0.00   0.00   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "4595   0.31   0.00   0.62    0.0   0.00   0.31   0.00   0.00   0.00   0.00   \n",
       "4596   0.00   0.00   0.00    0.0   0.00   0.00   0.00   0.00   0.00   0.00   \n",
       "4597   0.30   0.00   0.30    0.0   0.00   0.00   0.00   0.00   0.00   0.00   \n",
       "4598   0.96   0.00   0.00    0.0   0.32   0.00   0.00   0.00   0.00   0.00   \n",
       "4599   0.00   0.00   0.65    0.0   0.00   0.00   0.00   0.00   0.00   0.00   \n",
       "\n",
       "      ...  col_48  col_49  col_50  col_51  col_52  col_53  col_54  col_55  \\\n",
       "0     ...   0.000   0.132     0.0   0.372   0.180   0.048   5.114     101   \n",
       "1     ...   0.010   0.143     0.0   0.276   0.184   0.010   9.821     485   \n",
       "2     ...   0.000   0.137     0.0   0.137   0.000   0.000   3.537      40   \n",
       "3     ...   0.000   0.135     0.0   0.135   0.000   0.000   3.537      40   \n",
       "4     ...   0.000   0.223     0.0   0.000   0.000   0.000   3.000      15   \n",
       "...   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "4595  ...   0.000   0.232     0.0   0.000   0.000   0.000   1.142       3   \n",
       "4596  ...   0.000   0.000     0.0   0.353   0.000   0.000   1.555       4   \n",
       "4597  ...   0.102   0.718     0.0   0.000   0.000   0.000   1.404       6   \n",
       "4598  ...   0.000   0.057     0.0   0.000   0.000   0.000   1.147       5   \n",
       "4599  ...   0.000   0.000     0.0   0.125   0.000   0.000   1.250       5   \n",
       "\n",
       "      col_56  class  \n",
       "0       1028      1  \n",
       "1       2259      1  \n",
       "2        191      1  \n",
       "3        191      1  \n",
       "4         54      1  \n",
       "...      ...    ...  \n",
       "4595      88      0  \n",
       "4596      14      0  \n",
       "4597     118      0  \n",
       "4598      78      0  \n",
       "4599      40      0  \n",
       "\n",
       "[4600 rows x 58 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase_df = pd.read_csv(\"spambase.csv\")\n",
    "\n",
    "unique_column_names = [\"col_\" + str(i) for i in range(len(spambase_df.columns) - 1)] + [\"class\"]\n",
    "\n",
    "\n",
    "# Assign the unique names to the columns because my tree implementation uses column names\n",
    "spambase_df.columns = unique_column_names\n",
    "spambase_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45492026-a7f8-4f2f-a5ca-5b6e0db8cdbf",
   "metadata": {},
   "source": [
    "## Training tree on Spambase and using KFold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52c93053-3706-4c1a-9481-17d99700b46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "SB_LIMITS = [5, 10, 15, 20, 25] # Threshold limits to test\n",
    "SB_limit_means = []\n",
    "SB_limit_std = []\n",
    "\n",
    "for limit in SB_LIMITS:\n",
    "    accuracy_scores = []\n",
    "    for train_index, test_index in kf.split(spambase_df): # Split spambase dataframe for kfold\n",
    "\n",
    "        spambase_train, spambase_test = spambase_df.iloc[train_index], spambase_df.iloc[test_index]\n",
    "\n",
    "        tree = decision_tree(limit) # Create decision tree with appropriate limit\n",
    "        target = spambase_train.columns[-1]\n",
    "        tree.fit(spambase_train, target) # fit the tree using the training data and last column as target\n",
    "\n",
    "        spambase_pred = [tree.predict(row) for _, row in spambase_test.iterrows()] # get predictions array\n",
    "\n",
    "        accuracy = accuracy_score(spambase_test[target], spambase_pred) # calculate accuracy scores\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    accuracy_mean = np.mean(accuracy_scores)\n",
    "    accuracy_std = np.std(accuracy_scores)\n",
    "    SB_limit_means.append(accuracy_mean)\n",
    "    SB_limit_std.append(accuracy_std)\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73e62e7-98c0-4ad7-8d01-085e8d50dbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spambase results:\n",
      "   Min Thresholds  Accuracy Means  Std Deviations\n",
      "0               5        0.900870        0.017853\n",
      "1              10        0.888478        0.014323\n",
      "2              15        0.868261        0.023011\n",
      "3              20        0.858696        0.020300\n",
      "4              25        0.827609        0.016529\n"
     ]
    }
   ],
   "source": [
    "SB_table = pd.DataFrame({\n",
    "    'Min Thresholds': SB_LIMITS,\n",
    "    'Accuracy Means': SB_limit_means,\n",
    "    'Std Deviations': SB_limit_std\n",
    "})\n",
    "print(\"Spambase results:\")\n",
    "print(SB_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a11c56f-3704-4b8d-973e-6495680d1df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
